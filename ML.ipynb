{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f96cd169-a995-4d3a-98f7-05e4649c6ed7",
      "metadata": {
        "id": "f96cd169-a995-4d3a-98f7-05e4649c6ed7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b09c0fe5-449e-4162-860b-5336906d2ee3",
      "metadata": {
        "id": "b09c0fe5-449e-4162-860b-5336906d2ee3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c039a500-5de1-42b2-a885-17324bfd8481",
      "metadata": {
        "id": "c039a500-5de1-42b2-a885-17324bfd8481"
      },
      "outputs": [],
      "source": [
        "# Load the dataset(step 1 loading data and prepare)\n",
        "df = pd.read_csv('bank.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tXyxGxfgOdrh"
      },
      "id": "tXyxGxfgOdrh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aabcdf8a-207f-45b0-acf2-79d4e211c324",
      "metadata": {
        "id": "aabcdf8a-207f-45b0-acf2-79d4e211c324"
      },
      "outputs": [],
      "source": [
        "# Display the first few rows of the dataset\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36c00202-49d0-4389-8328-d2c6eb179adc",
      "metadata": {
        "id": "36c00202-49d0-4389-8328-d2c6eb179adc"
      },
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "df.isnull().sum()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d48fd042-a443-4dda-8031-77fd052440f3",
      "metadata": {
        "id": "d48fd042-a443-4dda-8031-77fd052440f3"
      },
      "outputs": [],
      "source": [
        "# Get an overview of the data types\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0e5b587-cec4-4043-bac7-3325688d6e16",
      "metadata": {
        "id": "d0e5b587-cec4-4043-bac7-3325688d6e16"
      },
      "outputs": [],
      "source": [
        "# Basic statistics\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7eee43f-249f-439f-9164-f2a0c2f47fe4",
      "metadata": {
        "id": "a7eee43f-249f-439f-9164-f2a0c2f47fe4"
      },
      "outputs": [],
      "source": [
        "# Drop missing values\n",
        "df = df.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7f1d43f-fc80-4732-b953-a23eaaedd66d",
      "metadata": {
        "id": "d7f1d43f-fc80-4732-b953-a23eaaedd66d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "282547ca-8faa-464b-bfba-7563c24f53a6",
      "metadata": {
        "id": "282547ca-8faa-464b-bfba-7563c24f53a6"
      },
      "outputs": [],
      "source": [
        "# step 2 EDA Exploratory Data Analysis\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f92e40b1-2ce6-4e0d-b948-39556ba4a75f",
      "metadata": {
        "id": "f92e40b1-2ce6-4e0d-b948-39556ba4a75f"
      },
      "outputs": [],
      "source": [
        "# Check the column names to see how they are formatted\n",
        "print(df.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2abe7ce9-6641-4f55-afe1-6f15415fc9e2",
      "metadata": {
        "id": "2abe7ce9-6641-4f55-afe1-6f15415fc9e2"
      },
      "outputs": [],
      "source": [
        "# Clean up column names by stripping whitespace or unwanted characters\n",
        "df.columns = df.columns.str.strip().str.replace('\"', '')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d8f7fe0-47fc-42f0-b450-ee12f9640fd1",
      "metadata": {
        "id": "1d8f7fe0-47fc-42f0-b450-ee12f9640fd1"
      },
      "outputs": [],
      "source": [
        "# Verify that column names are now clean\n",
        "print(df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51d6222c-f2c0-42e8-90b8-43b1261ccfeb",
      "metadata": {
        "id": "51d6222c-f2c0-42e8-90b8-43b1261ccfeb"
      },
      "outputs": [],
      "source": [
        "print(df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "328f6285-ea1b-47f1-bd1b-a07b19382142",
      "metadata": {
        "scrolled": true,
        "id": "328f6285-ea1b-47f1-bd1b-a07b19382142"
      },
      "outputs": [],
      "source": [
        "# Manually rename the columns\n",
        "df.rename(columns={\"\\\"age\\\"\": \"age\", \"age;\": \"age\"}, inplace=True)\n",
        "\n",
        "# Verify the change\n",
        "print(df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbd4c9db-af08-4267-8a27-84439ade814d",
      "metadata": {
        "id": "cbd4c9db-af08-4267-8a27-84439ade814d"
      },
      "outputs": [],
      "source": [
        "print(df.head)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0400d6a-601e-4e11-8168-c91f0a0ef120",
      "metadata": {
        "id": "c0400d6a-601e-4e11-8168-c91f0a0ef120"
      },
      "outputs": [],
      "source": [
        "# Re-read the dataset with semicolon separator\n",
        "df = pd.read_csv('bank.csv', sep=';')\n",
        "\n",
        "# Verify if columns are separated correctly now\n",
        "print(df.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "244df58f-a56b-4053-968b-d7f89df5c7b0",
      "metadata": {
        "scrolled": true,
        "id": "244df58f-a56b-4053-968b-d7f89df5c7b0"
      },
      "outputs": [],
      "source": [
        "sns.histplot(df['age'], bins=10)\n",
        "plt.title('Age Distribution')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26f6b719-d71d-42e8-a85b-b8dcee85c926",
      "metadata": {
        "id": "26f6b719-d71d-42e8-a85b-b8dcee85c926"
      },
      "outputs": [],
      "source": [
        "# Check the column names in your dataset\n",
        "print(data.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92a80749-4308-4003-b795-cd6168f2783b",
      "metadata": {
        "id": "92a80749-4308-4003-b795-cd6168f2783b"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "data = pd.read_csv('bank.csv', delimiter=';')\n",
        "\n",
        "# Inspect the first few rows to make sure the data is loaded\n",
        "print(data.head())\n",
        "# Step 2: Plot Age vs Balance\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.scatterplot(x='age', y='balance', data=data)\n",
        "plt.title('Age vs Balance')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b08f949b-9eb8-466d-ae7e-db75ecbe7b13",
      "metadata": {
        "id": "b08f949b-9eb8-466d-ae7e-db75ecbe7b13"
      },
      "outputs": [],
      "source": [
        "sns.countplot(x='job', data=data)\n",
        "plt.title('Job Distribution')\n",
        "plt.xticks(rotation=90)  # Rotate labels for better readability\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82938826-ca28-444f-9b0b-898a947579a1",
      "metadata": {
        "id": "82938826-ca28-444f-9b0b-898a947579a1"
      },
      "outputs": [],
      "source": [
        "sns.countplot(x='marital', data=data)\n",
        "plt.title('Marital Status Distribution')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08f3cdf7-3686-4a8b-85a0-9d4f27d2e28f",
      "metadata": {
        "id": "08f3cdf7-3686-4a8b-85a0-9d4f27d2e28f"
      },
      "outputs": [],
      "source": [
        "sns.countplot(x='education', data=data)\n",
        "plt.title('Education Distribution')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24e796de-33bc-4ed6-8d9a-c51e0eed8b8c",
      "metadata": {
        "id": "24e796de-33bc-4ed6-8d9a-c51e0eed8b8c"
      },
      "outputs": [],
      "source": [
        "# Job vs Education (Count Plot)\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.countplot(x='job', hue='education', data=data)\n",
        "plt.title('Job vs Education')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "156d493b-0932-41df-b70b-d3f84223e7e4",
      "metadata": {
        "id": "156d493b-0932-41df-b70b-d3f84223e7e4"
      },
      "outputs": [],
      "source": [
        "# Job vs Campaign (Box Plot)\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.boxplot(x='job', y='campaign', data=data)\n",
        "plt.title('Job vs Campaign')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5914ae65-40e0-4cc1-84a1-22324e954f7b",
      "metadata": {
        "id": "5914ae65-40e0-4cc1-84a1-22324e954f7b"
      },
      "outputs": [],
      "source": [
        "# Job vs Housing (Count Plot)\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.countplot(x='job', hue='housing', data=data)\n",
        "plt.title('Job vs Housing')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4592c51a-2cc0-43ef-bf31-68bd731adbd2",
      "metadata": {
        "id": "4592c51a-2cc0-43ef-bf31-68bd731adbd2"
      },
      "outputs": [],
      "source": [
        "# Correlation Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fab4b067-d06a-4d8a-bd63-9fdde5adc614",
      "metadata": {
        "id": "fab4b067-d06a-4d8a-bd63-9fdde5adc614"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "corr_matrix = data.corr()\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24fe2fd3-a161-412b-9807-c39537135c9b",
      "metadata": {
        "id": "24fe2fd3-a161-412b-9807-c39537135c9b"
      },
      "outputs": [],
      "source": [
        "# Target Variable Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b48b7c8-8e82-4f16-ae7c-48850c6f0d8f",
      "metadata": {
        "id": "3b48b7c8-8e82-4f16-ae7c-48850c6f0d8f"
      },
      "outputs": [],
      "source": [
        "sns.countplot(x='y', data=data)\n",
        "plt.title('Subscription Outcome Distribution')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5827fc9-441d-494a-822c-81a39331cdd4",
      "metadata": {
        "id": "b5827fc9-441d-494a-822c-81a39331cdd4"
      },
      "outputs": [],
      "source": [
        "# Relationship Between Categorical Features and Target Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b87e246e-e901-4f83-bb04-854a56afc001",
      "metadata": {
        "id": "b87e246e-e901-4f83-bb04-854a56afc001"
      },
      "outputs": [],
      "source": [
        "sns.countplot(x='job', hue='y', data=data)\n",
        "plt.title('Subscription Outcome by Job')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f14c506-b7ff-43a1-8fab-9e56ac0fe9a5",
      "metadata": {
        "id": "5f14c506-b7ff-43a1-8fab-9e56ac0fe9a5"
      },
      "outputs": [],
      "source": [
        "sns.countplot(x='marital', hue='y', data=data)\n",
        "plt.title('Subscription Outcome by Marital Status')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f9fb706-e41f-4aa8-bd9d-546490ae71a9",
      "metadata": {
        "id": "9f9fb706-e41f-4aa8-bd9d-546490ae71a9"
      },
      "outputs": [],
      "source": [
        "#  Numerical Variables vs Target Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f926c86c-c297-4d2c-b0be-ef3c5a623877",
      "metadata": {
        "id": "f926c86c-c297-4d2c-b0be-ef3c5a623877"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(x='y', y='balance', data=data)\n",
        "plt.title('Balance vs Subscription Outcome')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d2f2432-fc71-4b28-a240-37dec5f15007",
      "metadata": {
        "id": "8d2f2432-fc71-4b28-a240-37dec5f15007"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(x='y', y='duration', data=data)\n",
        "plt.title('Duration vs Subscription Outcome')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "403b3bb4-126c-4fe6-96cb-2db2f4d5e539",
      "metadata": {
        "id": "403b3bb4-126c-4fe6-96cb-2db2f4d5e539"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b33e917-c602-4b91-bf84-c056751ae6e2",
      "metadata": {
        "id": "0b33e917-c602-4b91-bf84-c056751ae6e2"
      },
      "outputs": [],
      "source": [
        "# STEP 3 1. Identify Categorical and Numerical Variables, 2. Handle Missing Values,3. Encode Categorical Variables, 4. Encode the Target Variable, 5. Scale Numerical Features, 6. Feature Selection (Optional but Recommended), 7. Final Data Inspection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "253a328c-fc3b-4625-b4dd-869592f894e6",
      "metadata": {
        "id": "253a328c-fc3b-4625-b4dd-869592f894e6"
      },
      "outputs": [],
      "source": [
        "# Encode categorical features(step 3 data prepocessing)\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68ed3360-128b-4d17-8984-f970e982ecad",
      "metadata": {
        "id": "68ed3360-128b-4d17-8984-f970e982ecad"
      },
      "outputs": [],
      "source": [
        "# Handling missing data\n",
        "# Option 1: Remove rows with missing values\n",
        "data_encoded = data_encoded.dropna()\n",
        "\n",
        "# Define numerical and categorical columns\n",
        "numerical_columns = data_encoded.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_columns = data_encoded.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "# Now proceed with the missing value handling as before\n",
        "\n",
        "# Imputation for numerical data\n",
        "num_imputer = SimpleImputer(strategy='mean')\n",
        "data_encoded[numerical_columns] = num_imputer.fit_transform(data_encoded[numerical_columns])\n",
        "\n",
        "# Imputation for categorical data\n",
        "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
        "data_encoded[categorical_columns] = cat_imputer.fit_transform(data_encoded[categorical_columns])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff4034ef-c5a1-492c-bb42-29d06116d082",
      "metadata": {
        "id": "ff4034ef-c5a1-492c-bb42-29d06116d082"
      },
      "outputs": [],
      "source": [
        "# Ensure numerical columns are defined\n",
        "numerical_columns = data_encoded.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "# Outlier detection using IQR (Interquartile Range)\n",
        "Q1 = data_encoded[numerical_columns].quantile(0.25)\n",
        "Q3 = data_encoded[numerical_columns].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Define outliers as points outside 1.5*IQR from Q1 and Q3\n",
        "outliers = (data_encoded[numerical_columns] < (Q1 - 1.5 * IQR)) | (data_encoded[numerical_columns] > (Q3 + 1.5 * IQR))\n",
        "\n",
        "# Option 1: Removing outliers\n",
        "# This will remove rows with outliers in any numerical column\n",
        "data_encoded = data_encoded[~outliers.any(axis=1)]\n",
        "\n",
        "# Option 2: You can also handle outliers differently, such as capping them\n",
        "# Example for capping:\n",
        "# data_encoded[numerical_columns] = data_encoded[numerical_columns].apply(\n",
        "#     lambda x: np.where(x < (Q1 - 1.5 * IQR), Q1 - 1.5 * IQR, np.where(x > (Q3 + 1.5 * IQR), Q3 + 1.5 * IQR, x))\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a554e906-61ba-4695-a999-6d7a7ddc458b",
      "metadata": {
        "id": "a554e906-61ba-4695-a999-6d7a7ddc458b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "673f751b-d553-48c2-a39f-60c3375110c5",
      "metadata": {
        "id": "673f751b-d553-48c2-a39f-60c3375110c5"
      },
      "outputs": [],
      "source": [
        "# Print the first few rows of encoded dataset\n",
        "df_encoded = pd.get_dummies(df, drop_first=True)\n",
        "print(df_encoded.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7664d5ac-b09e-4394-8162-da4d9a7c7123",
      "metadata": {
        "id": "7664d5ac-b09e-4394-8162-da4d9a7c7123"
      },
      "outputs": [],
      "source": [
        "# Features (X) and Target (y)\n",
        "X = df_encoded.drop('y_yes', axis=1)  # 'y_yes' is the target variable (1 for yes, 0 for no)\n",
        "y = df_encoded['y_yes']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35cc81bb-dca7-469e-aa8d-0761625090f3",
      "metadata": {
        "id": "35cc81bb-dca7-469e-aa8d-0761625090f3"
      },
      "outputs": [],
      "source": [
        "# Split data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc14bceb-6243-47cf-8e11-dde25ddf906c",
      "metadata": {
        "id": "dc14bceb-6243-47cf-8e11-dde25ddf906c"
      },
      "outputs": [],
      "source": [
        "# Import the necessary module for scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train the Logistic Regression model with scaled data\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train_scaled, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c787754a-26a8-4cae-b41d-c0a7f877dcbf",
      "metadata": {
        "id": "c787754a-26a8-4cae-b41d-c0a7f877dcbf"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60ca46b4-251d-40f2-b601-317072d28221",
      "metadata": {
        "id": "60ca46b4-251d-40f2-b601-317072d28221"
      },
      "outputs": [],
      "source": [
        "# Import evaluation metrics\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f2a6e71-ef1d-48b6-b61c-99545761cbf9",
      "metadata": {
        "id": "3f2a6e71-ef1d-48b6-b61c-99545761cbf9"
      },
      "outputs": [],
      "source": [
        "print(data.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37a7831e-f8d2-4524-8e65-4ba133885046",
      "metadata": {
        "id": "37a7831e-f8d2-4524-8e65-4ba133885046"
      },
      "outputs": [],
      "source": [
        "# Assuming 'data' is your DataFrame\n",
        "data = data[data.columns[0]].str.split(';', expand=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "580ecf3e-0f6e-4cd0-baa7-d7d96a8e5a18",
      "metadata": {
        "id": "580ecf3e-0f6e-4cd0-baa7-d7d96a8e5a18"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9500fc3d-d4fd-40ce-bf1e-0b9a68ef0c92",
      "metadata": {
        "id": "9500fc3d-d4fd-40ce-bf1e-0b9a68ef0c92"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load your dataset DATA LOADINNG ND INITIAL PREPARATION\n",
        "# Sample dataframe for demonstration (replace this with your actual data loading step)\n",
        "data = pd.DataFrame({\n",
        "    'data': ['30;unemployed;married;primary;no;1787;no;no;cellular;19;oct;79;1;-1;0;unknown;no',\n",
        "             '33;services;married;secondary;no;4789;yes;yes;cellular;11;may;220;1;339;4;failure;no',\n",
        "             '35;management;single;tertiary;no;1350;yes;no;cellular;16;apr;185;1;330;1;failure;no']\n",
        "})\n",
        "\n",
        "# Split the single column into multiple columns based on the semicolon (;) DATA CLEANING\n",
        "data = data['data'].str.split(';', expand=True)\n",
        "\n",
        "# Assign the correct column names\n",
        "data.columns = ['age', 'job', 'marital', 'education', 'default', 'balance',\n",
        "                'housing', 'loan', 'contact', 'day', 'month', 'duration',\n",
        "                'campaign', 'pdays', 'previous', 'poutcome', 'y']\n",
        "\n",
        "# Convert numeric columns from string to their appropriate types\n",
        "data['age'] = data['age'].astype(int)\n",
        "data['balance'] = data['balance'].astype(float)\n",
        "data['day'] = data['day'].astype(int)\n",
        "data['duration'] = data['duration'].astype(int)\n",
        "data['campaign'] = data['campaign'].astype(int)\n",
        "data['pdays'] = data['pdays'].astype(int)\n",
        "data['previous'] = data['previous'].astype(int)\n",
        "\n",
        "# List of categorical columns for encoding\n",
        "categorical_cols = ['job', 'marital', 'education', 'default', 'housing',\n",
        "                    'loan', 'contact', 'month', 'poutcome', 'y']  # Include 'y' if it's categorical\n",
        "\n",
        "# One-Hot Encoding using pandas.get_dummies FEATURE ENGINEERING\n",
        "data_encoded = pd.get_dummies(data, columns=categorical_cols, drop_first=True)\n",
        "\n",
        "# Inspect the new columns\n",
        "print(\"Encoded Data Columns:\")\n",
        "print(data_encoded.columns)  # Check if 'y' is included\n",
        "\n",
        "# Check for correlation EXPLORATORY DATA ANALYSIS(EDA)\n",
        "plt.figure(figsize=(12, 8))\n",
        "corr_matrix = data_encoded.corr()\n",
        "\n",
        "# Print the correlation matrix to debug\n",
        "print(\"Correlation Matrix:\")\n",
        "print(corr_matrix)  # Check the correlation matrix\n",
        "\n",
        "# Now plot the heatmap\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')  # Set annot=True to see the correlation values\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Ensure 'y' is in the correlation matrix before trying to access it FEATURE SELECTION\n",
        "if 'y' in corr_matrix.columns:\n",
        "    # Identify features with low correlation with target 'y'\n",
        "    low_corr_features = corr_matrix['y'][corr_matrix['y'].abs() < 0.05].index.tolist()\n",
        "    print(\"Low correlation features:\", low_corr_features)\n",
        "\n",
        "    # Drop low correlation features if necessary\n",
        "    data_encoded.drop(low_corr_features, axis=1, inplace=True)\n",
        "else:\n",
        "    print(\"'y' is not present in the correlation matrix.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c2cfc7d-8a25-4f97-8a54-774acead80b2",
      "metadata": {
        "id": "4c2cfc7d-8a25-4f97-8a54-774acead80b2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "443d4cb1-af36-47be-9430-aa3410d849fc",
      "metadata": {
        "id": "443d4cb1-af36-47be-9430-aa3410d849fc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf508662-448f-476c-a43e-bcc51dd728ce",
      "metadata": {
        "id": "cf508662-448f-476c-a43e-bcc51dd728ce"
      },
      "outputs": [],
      "source": [
        "pip install category_encoders\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "672ad2d6-42d9-45b3-8644-83bd5abc3660",
      "metadata": {
        "scrolled": true,
        "id": "672ad2d6-42d9-45b3-8644-83bd5abc3660"
      },
      "outputs": [],
      "source": [
        "print(data_encoded.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88785517-ee1b-448a-b524-2a9771e89bb6",
      "metadata": {
        "id": "88785517-ee1b-448a-b524-2a9771e89bb6"
      },
      "outputs": [],
      "source": [
        "print(data_encoded.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "479e85e7-4dae-4aab-95b8-cc27c055caed",
      "metadata": {
        "id": "479e85e7-4dae-4aab-95b8-cc27c055caed"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Create a synthetic target for binary classification (0 or 1)\n",
        "data_encoded['target'] = np.random.choice([0, 1], size=len(data_encoded))\n",
        "\n",
        "# Now proceed with encoding\n",
        "from category_encoders import TargetEncoder\n",
        "target_encoder = TargetEncoder()\n",
        "data_encoded['job_services_encoded'] = target_encoder.fit_transform(data_encoded['job_services'], data_encoded['target'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d418487-04b9-4721-a5f5-84ffc1d2b4ba",
      "metadata": {
        "id": "2d418487-04b9-4721-a5f5-84ffc1d2b4ba"
      },
      "outputs": [],
      "source": [
        "print(data_encoded.dtypes)\n",
        "# Ensure 'job_services' is in the correct format for target encoding\n",
        "data_encoded['job_services'] = data_encoded['job_services'].astype('category')\n",
        "\n",
        "# Apply target encoding\n",
        "from category_encoders import TargetEncoder\n",
        "target_encoder = TargetEncoder()\n",
        "data_encoded['job_services_encoded'] = target_encoder.fit_transform(data_encoded['job_services'], data_encoded['target'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ced9fa7-2d8c-4802-8dfc-012b73813950",
      "metadata": {
        "id": "2ced9fa7-2d8c-4802-8dfc-012b73813950"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffbdaddd-a91e-4a27-a88e-35649413c23e",
      "metadata": {
        "scrolled": true,
        "id": "ffbdaddd-a91e-4a27-a88e-35649413c23e"
      },
      "outputs": [],
      "source": [
        "# Identifying numerical columns\n",
        "numerical_columns = data_encoded.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "# Scaling numerical data\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "# Option 1: Standardization (mean=0, std=1)\n",
        "scaler = StandardScaler()\n",
        "data_encoded[numerical_columns] = scaler.fit_transform(data_encoded[numerical_columns])\n",
        "\n",
        "# Option 2: Min-Max scaling (scaling to [0, 1])\n",
        "scaler = MinMaxScaler()\n",
        "data_encoded[numerical_columns] = scaler.fit_transform(data_encoded[numerical_columns])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ef01715-a266-48ff-92a5-4eb3a042b795",
      "metadata": {
        "id": "3ef01715-a266-48ff-92a5-4eb3a042b795"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5901cea-d295-47d4-babc-1d0d2aa49474",
      "metadata": {
        "id": "f5901cea-d295-47d4-babc-1d0d2aa49474"
      },
      "outputs": [],
      "source": [
        "# MODEL SELECTION AND TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73e311fe-f7ed-4905-bab2-c17447ea93b3",
      "metadata": {
        "id": "73e311fe-f7ed-4905-bab2-c17447ea93b3"
      },
      "outputs": [],
      "source": [
        "# Splitting the Data into Training and Testing Sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92d4d444-6ded-4a44-9557-c4c3738a02f0",
      "metadata": {
        "id": "92d4d444-6ded-4a44-9557-c4c3738a02f0"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Features (X) and target (y)\n",
        "X = data_encoded.drop(columns=['target'])  # Drop the target column from the features\n",
        "y = data_encoded['target']  # Target variable\n",
        "\n",
        "# Split the data into 80% training and 20% testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "beddb493-c791-4e3b-8eeb-32b493a8d5cc",
      "metadata": {
        "id": "beddb493-c791-4e3b-8eeb-32b493a8d5cc"
      },
      "outputs": [],
      "source": [
        "# Model Selection:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0aa41dfd-f66c-46e7-a454-ea497dc06289",
      "metadata": {
        "id": "0aa41dfd-f66c-46e7-a454-ea497dc06289"
      },
      "outputs": [],
      "source": [
        "print(X_train.columns)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afe08aa7-c02f-45f9-ba5d-5adc78cfe274",
      "metadata": {
        "id": "afe08aa7-c02f-45f9-ba5d-5adc78cfe274"
      },
      "outputs": [],
      "source": [
        "print(y_train.unique())\n",
        "\n",
        "# Check unique classes in the target variable\n",
        "print(y_train.value_counts())\n",
        "\n",
        "# If there's only one class, consider resampling or obtaining more data\n",
        "if y_train.nunique() < 2:\n",
        "    print(\"Only one class found in y_train. Please check your dataset.\")\n",
        "else:\n",
        "    # Proceed to fit the model\n",
        "    model.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43b16e1c-2a62-410c-b378-87e57f0386e4",
      "metadata": {
        "id": "43b16e1c-2a62-410c-b378-87e57f0386e4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae15f4b6-5b19-434f-a084-11e957e0da19",
      "metadata": {
        "id": "ae15f4b6-5b19-434f-a084-11e957e0da19"
      },
      "outputs": [],
      "source": [
        "print(X_train.columns)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59ac550b-1482-4938-b5e3-ed39180cdfa2",
      "metadata": {
        "id": "59ac550b-1482-4938-b5e3-ed39180cdfa2"
      },
      "outputs": [],
      "source": [
        "# Check the columns to ensure you know what you're working with\n",
        "print(X_train.columns)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b8734d9-ed96-4332-b9e1-30332d0afc0d",
      "metadata": {
        "id": "9b8734d9-ed96-4332-b9e1-30332d0afc0d"
      },
      "outputs": [],
      "source": [
        "print(X.columns)  # Assuming X is your original features DataFrame\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "add1cf0c-c85f-4875-a1f4-6d95f1aeb1ec",
      "metadata": {
        "id": "add1cf0c-c85f-4875-a1f4-6d95f1aeb1ec"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Print the columns to check their names\n",
        "print(\"X_train columns:\", X_train.columns)\n",
        "print(\"X_test columns:\", X_test.columns)\n",
        "\n",
        "# Assuming the column exists and is correctly named:\n",
        "if 'job_services' in X_train.columns and 'job_services' in X_test.columns:\n",
        "    # Split the job_services column by commas and explode to create separate rows\n",
        "    X_train['job_services'] = X_train['job_services'].str.split(',')\n",
        "    X_test['job_services'] = X_test['job_services'].str.split(',')\n",
        "\n",
        "    # Now, explode the lists into separate rows\n",
        "    X_train_exploded = X_train.explode('job_services')\n",
        "    X_test_exploded = X_test.explode('job_services')\n",
        "\n",
        "    # Proceed with encoding or further processing\n",
        "else:\n",
        "    print(\"Column 'job_services' is missing in either X_train or X_test.\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d4da6e9-f058-44d5-bb45-d57d21dbb573",
      "metadata": {
        "id": "2d4da6e9-f058-44d5-bb45-d57d21dbb573"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39121ba1-bb4a-4984-af62-3f8c5a3400da",
      "metadata": {
        "id": "39121ba1-bb4a-4984-af62-3f8c5a3400da"
      },
      "outputs": [],
      "source": [
        "# Install necessary packages if you haven't already\n",
        "!pip install pandas numpy scikit-learn matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "056f6667-61ef-4e3b-af16-94baff33de6d",
      "metadata": {
        "id": "056f6667-61ef-4e3b-af16-94baff33de6d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b9fe596-9596-49a8-bc60-da5c3735c301",
      "metadata": {
        "id": "9b9fe596-9596-49a8-bc60-da5c3735c301"
      },
      "outputs": [],
      "source": [
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a65f5e77-a7ac-47f4-9973-6aaff58e5f61",
      "metadata": {
        "id": "a65f5e77-a7ac-47f4-9973-6aaff58e5f61"
      },
      "outputs": [],
      "source": [
        "# Check the column names in the dataset\n",
        "print(data.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8175b07d-56a8-4c67-be8b-58aa6c2403f2",
      "metadata": {
        "id": "8175b07d-56a8-4c67-be8b-58aa6c2403f2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file with the correct delimiter\n",
        "data = pd.read_csv('bank.csv', sep=';')\n",
        "\n",
        "# Check the corrected column names\n",
        "print(data.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e247ec7-688d-449a-a4cf-0959b98f633d",
      "metadata": {
        "id": "2e247ec7-688d-449a-a4cf-0959b98f633d"
      },
      "outputs": [],
      "source": [
        "# Define your features (X) and target (y)\n",
        "X = data.drop('y', axis=1)  # 'y' is the target column\n",
        "y = data['y']\n",
        "\n",
        "# Now split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Print the shape of X_train to verify\n",
        "print(f'Number of training samples: {X_train.shape[0]}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f87f8688-58cd-4b34-8588-3cf89ca4349d",
      "metadata": {
        "id": "f87f8688-58cd-4b34-8588-3cf89ca4349d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f796a2d-c0ff-4e78-9ba4-fee594f6abd9",
      "metadata": {
        "id": "3f796a2d-c0ff-4e78-9ba4-fee594f6abd9"
      },
      "outputs": [],
      "source": [
        "# Hyperparameter Tuning:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b039849-c2b0-48c2-b661-b83162606317",
      "metadata": {
        "id": "1b039849-c2b0-48c2-b661-b83162606317"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load your dataset (ensure to use the correct delimiter)\n",
        "df = pd.read_csv('bank.csv', sep=';')  # Use ';' as the separator if needed\n",
        "\n",
        "# Print columns to verify\n",
        "print(\"Columns in the dataset:\")\n",
        "print(df.columns)\n",
        "\n",
        "# Target column\n",
        "target_column = 'y'  # The target column is confirmed to be 'y'\n",
        "\n",
        "# Define features and target variable\n",
        "X = df.drop(columns=[target_column])  # Drop the target column to get features\n",
        "y = df[target_column]  # Target variable\n",
        "\n",
        "# Convert categorical variables to numerical using one-hot encoding\n",
        "X = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Initialize the model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Hyperparameter tuning\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],\n",
        "    'solver': ['liblinear', 'saga'],\n",
        "    'max_iter': [100, 200, 300]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(\"Best Hyperparameters:\")\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred_best = best_model.predict(X_test_scaled)\n",
        "\n",
        "print(\"Confusion Matrix for Best Model:\")\n",
        "print(confusion_matrix(y_test, y_pred_best))\n",
        "\n",
        "print(\"\\nClassification Report for Best Model:\")\n",
        "print(classification_report(y_test, y_pred_best))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5f83e96-fe3f-498a-ad94-b89b1bfffbae",
      "metadata": {
        "id": "a5f83e96-fe3f-498a-ad94-b89b1bfffbae"
      },
      "outputs": [],
      "source": [
        "print(df.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ed51bb7-4d28-48e0-b871-9b91521a168a",
      "metadata": {
        "id": "6ed51bb7-4d28-48e0-b871-9b91521a168a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9646e668-aa92-4f9a-aae8-da5e87bed04f",
      "metadata": {
        "id": "9646e668-aa92-4f9a-aae8-da5e87bed04f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62c6d19a-b418-4761-8f62-fa9b6f6efa41",
      "metadata": {
        "id": "62c6d19a-b418-4761-8f62-fa9b6f6efa41"
      },
      "outputs": [],
      "source": [
        "# Model Evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c224f0b-9992-47d5-a5f3-eefdec623ccb",
      "metadata": {
        "id": "5c224f0b-9992-47d5-a5f3-eefdec623ccb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7435964e-699d-480f-b0b9-66d26e277d95",
      "metadata": {
        "id": "7435964e-699d-480f-b0b9-66d26e277d95"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load your dataset (ensure to use the correct delimiter)\n",
        "df = pd.read_csv('bank.csv', sep=';')  # Use ';' as the separator if needed\n",
        "\n",
        "# Print columns to verify\n",
        "print(\"Columns in the dataset:\")\n",
        "print(df.columns)\n",
        "\n",
        "# Target column\n",
        "target_column = 'y'  # The target column is confirmed to be 'y'\n",
        "\n",
        "# Define features and target variable\n",
        "X = df.drop(columns=[target_column])  # Drop the target column to get features\n",
        "y = df[target_column]  # Target variable\n",
        "\n",
        "# Convert categorical variables to numerical using one-hot encoding\n",
        "X = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Save the scaled datasets to CSV files\n",
        "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)  # Create DataFrame for training features\n",
        "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test.columns)  # Create DataFrame for testing features\n",
        "\n",
        "# Save the target variables to CSV files\n",
        "y_train_df = pd.DataFrame(y_train).reset_index(drop=True)\n",
        "y_test_df = pd.DataFrame(y_test).reset_index(drop=True)\n",
        "\n",
        "# Combine features and targets for saving\n",
        "train_data = pd.concat([X_train_scaled_df, y_train_df], axis=1)\n",
        "test_data = pd.concat([X_test_scaled_df, y_test_df], axis=1)\n",
        "\n",
        "# Save to CSV\n",
        "train_data.to_csv('train_data_scaled.csv', index=False)\n",
        "test_data.to_csv('test_data_scaled.csv', index=False)\n",
        "\n",
        "print(\"Training and testing datasets saved successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02a0a080-825a-412c-8c73-3eabc7963f94",
      "metadata": {
        "id": "02a0a080-825a-412c-8c73-3eabc7963f94"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "948c97e7-25d5-48b1-abaf-1b39d3f2620b",
      "metadata": {
        "id": "948c97e7-25d5-48b1-abaf-1b39d3f2620b"
      },
      "outputs": [],
      "source": [
        "print(data_encoded.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f89faebb-7fc6-476d-97ee-ec7eab1035a3",
      "metadata": {
        "id": "f89faebb-7fc6-476d-97ee-ec7eab1035a3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe948b26-2fa7-4bab-b0f1-a49154046188",
      "metadata": {
        "id": "fe948b26-2fa7-4bab-b0f1-a49154046188"
      },
      "outputs": [],
      "source": [
        "# Load your dataset\n",
        "data = pd.read_csv('bank.csv')  # Replace with your actual dataset path\n",
        "\n",
        "# Check the columns of the dataset\n",
        "print(\"Columns in the dataset:\")\n",
        "print(data.columns.tolist())  # List all column names to find the target variable\n",
        "\n",
        "# Strip whitespace from column names if needed\n",
        "data.columns = data.columns.str.strip()\n",
        "\n",
        "# Use the actual target column name after checking the output above\n",
        "target_column = 'Outcome'  # Replace with the actual target column name\n",
        "\n",
        "# Check if the target column exists\n",
        "if target_column not in data.columns:\n",
        "    print(f\"Target column '{target_column}' not found. Please check the column names.\")\n",
        "else:\n",
        "    # Split data into features and target variable\n",
        "    X = data.drop(target_column, axis=1)  # Use the actual target column name\n",
        "    y = data[target_column]  # This should be your target variable\n",
        "\n",
        "    # Split the dataset into training and test sets with a smaller test size\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)  # Adjust as needed\n",
        "\n",
        "    # Train a Random Forest classifier\n",
        "    model = RandomForestClassifier(random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Cross-validation scores with adjusted n_splits\n",
        "    cv_scores = cross_val_score(model, X_train, y_train, cv=2)  # Use cv=2\n",
        "    print(f'Cross-validation scores: {cv_scores}')\n",
        "    print(f'Mean CV score: {np.mean(cv_scores)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b661cda4-4db7-462e-b507-a1371bf4c6f9",
      "metadata": {
        "id": "b661cda4-4db7-462e-b507-a1371bf4c6f9"
      },
      "outputs": [],
      "source": [
        "# Deployment and Decision Support"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f82e8191-28f9-4fe8-b33d-49c95d06e472",
      "metadata": {
        "id": "f82e8191-28f9-4fe8-b33d-49c95d06e472"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('bank.csv')  # Replace with your dataset path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70f144fd-2e74-4920-b109-6257637c271f",
      "metadata": {
        "id": "70f144fd-2e74-4920-b109-6257637c271f"
      },
      "outputs": [],
      "source": [
        "# 1. Export Model Predictions to Excel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0db00cf2-bc97-45e6-846a-3c3b2ea0374a",
      "metadata": {
        "id": "0db00cf2-bc97-45e6-846a-3c3b2ea0374a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming `y_pred` contains your predictions and `X_test` contains your test features\n",
        "predictions_df = X_test.copy()\n",
        "predictions_df['Predicted'] = y_pred  # Add predictions to the DataFrame\n",
        "\n",
        "# Save to Excel\n",
        "predictions_df.to_excel('model_predictions.xlsx', index=False)\n",
        "print(\"Predictions exported to 'model_predictions.xlsx'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "656d99bd-4324-4948-8030-110452662524",
      "metadata": {
        "id": "656d99bd-4324-4948-8030-110452662524"
      },
      "outputs": [],
      "source": [
        "# 2. Visualize Key Insights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63d483e2-bc3c-494e-a4a1-6e6c15081423",
      "metadata": {
        "id": "63d483e2-bc3c-494e-a4a1-6e6c15081423"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "# Create confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a15e8eb9-09a5-4438-be01-7bdbb14c7fbc",
      "metadata": {
        "id": "a15e8eb9-09a5-4438-be01-7bdbb14c7fbc"
      },
      "outputs": [],
      "source": [
        "# 3. Deploying the Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression  # Example model\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load your data\n",
        "train_data = pd.read_csv('train_data_scaled.csv')\n",
        "test_data = pd.read_csv('test_data_scaled.csv')\n",
        "\n",
        "# Assume 'y' is the target column and the rest are features\n",
        "X_train = train_data.drop('y', axis=1)  # Features\n",
        "y_train = train_data['y']               # Target\n",
        "\n",
        "# Train the model (example using Logistic Regression)\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Save the trained model to a .pkl file\n",
        "joblib.dump(model, 'model_predictions.pkl')\n",
        "\n",
        "# You can load it again like this:\n",
        "# loaded_model = joblib.load('model_predictions.pkl')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29f1741f-5f44-4612-9b5a-7db136b7cacb",
        "id": "m01ZR_7JWRcp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['model_predictions.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "id": "m01ZR_7JWRcp"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your data\n",
        "train_data = pd.read_csv('train_data_scaled.csv')\n",
        "\n",
        "# Check the column names in the dataset\n",
        "print(train_data.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXYX6o6qSV0L",
        "outputId": "c02f7372-d836-4393-9cb6-3e424f11c549"
      },
      "id": "tXYX6o6qSV0L",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous',\n",
            "       'job_blue-collar', 'job_entrepreneur', 'job_housemaid',\n",
            "       'job_management', 'job_retired', 'job_self-employed', 'job_services',\n",
            "       'job_student', 'job_technician', 'job_unemployed', 'job_unknown',\n",
            "       'marital_married', 'marital_single', 'education_secondary',\n",
            "       'education_tertiary', 'education_unknown', 'default_yes', 'housing_yes',\n",
            "       'loan_yes', 'contact_telephone', 'contact_unknown', 'month_aug',\n",
            "       'month_dec', 'month_feb', 'month_jan', 'month_jul', 'month_jun',\n",
            "       'month_mar', 'month_may', 'month_nov', 'month_oct', 'month_sep',\n",
            "       'poutcome_other', 'poutcome_success', 'poutcome_unknown', 'y'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "db17de67-323b-4c24-921e-8a963aa3bd47",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db17de67-323b-4c24-921e-8a963aa3bd47",
        "outputId": "ef885b25-ec9c-42f6-9c53-efb56768960b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug: * Restarting with stat\n"
          ]
        }
      ],
      "source": [
        "from flask import Flask, request, jsonify\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Load the trained model\n",
        "with open('model_predictions.pkl', 'rb') as model_file:\n",
        "    model = pickle.load(model_file)\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    data = request.get_json(force=True)\n",
        "    # Convert input data to a numpy array\n",
        "    input_data = np.array(data['features']).reshape(1, -1)\n",
        "    # Make prediction\n",
        "    prediction = model.predict(input_data)\n",
        "    return jsonify({'prediction': prediction[0]})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}